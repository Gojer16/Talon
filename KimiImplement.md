# Kimi - Missing Features Roadmap

> **What's Left**: Smart routing and advanced memory features.

## âœ… Already Complete (v0.3.1 - 85%)
- Core agent loop with tool calling
- Memory compression (â‰¤800 token summaries)
- Model routing (DeepSeek â†’ OpenRouter â†’ OpenAI)
- Context management (last 5-10 messages only)
- Web search, file tools, shell tools, memory tools
- Multi-channel support (CLI, TUI, Telegram, WhatsApp)
- **Subagent System** (research, writer, planner, critic, summarizer) âœ…
- **Productivity Tools** (notes, tasks, Apple integrations) âœ…
- **Browser Control** (5 Puppeteer tools) âœ…
- **Shadow Loop** (proactive intelligence) âœ…

---

## ğŸš§ MISSING IMPLEMENTATIONS

### 1. Subagent Execution System âœ… COMPLETE

**Status:** âœ… Fully implemented and tested in v0.3.1

**What Was Built:**
```
src/subagents/
â”œâ”€â”€ base.ts           # Base subagent class âœ…
â”œâ”€â”€ registry.ts       # Subagent registry âœ…
â”œâ”€â”€ research.ts       # Research subagent âœ…
â”œâ”€â”€ writer.ts         # Content creation âœ…
â”œâ”€â”€ planner.ts        # Task planning âœ…
â”œâ”€â”€ critic.ts         # Work review âœ…
â”œâ”€â”€ summarizer.ts     # Text compression âœ…
â””â”€â”€ types.ts          # Type definitions âœ…

src/tools/
â””â”€â”€ subagent-tool.ts  # delegate_to_subagent tool âœ…
```

**Implementation Details:**
- âœ… `buildSubAgentPrompt()` in `src/agent/prompts.ts`
- âœ… Spawning/routing logic via SubagentRegistry
- âœ… JSON result parsing with structured outputs
- âœ… Task delegation via `delegate_to_subagent` tool
- âœ… Integrated into gateway Phase 3 initialization
- âœ… Configurable model via `agent.subagentModel`
- âœ… All 19 TDD tests passing
- âœ… Cost optimization: 97% savings using cheap models

**Usage:**
```json
// config.json
{
  "agent": {
    "subagentModel": "openrouter/openai/gpt-4o-mini"
  }
}
```

Agent can now delegate tasks:
- Research: Gather information with sources
- Writer: Produce content in various formats
- Planner: Create actionable plans with risks
- Critic: Review work with ratings and feedback
- Summarizer: Compress text into key points

---

### 2. Productivity Tools âœ… COMPLETE

**Status:** âœ… Fully implemented in v0.3.1

**What Was Built:**
```
src/tools/
â”œâ”€â”€ notes.ts              # Save/search notes âœ…
â”œâ”€â”€ tasks.ts              # Todo list management âœ…
â”œâ”€â”€ apple-notes.ts        # Apple Notes integration (macOS) âœ…
â”œâ”€â”€ apple-reminders.ts    # Apple Reminders (macOS) âœ…
â””â”€â”€ apple-calendar.ts     # Apple Calendar (macOS) âœ…
```

**Implemented Tools:**

**Local Tools:**
- âœ… `notes_save` - Save notes with tags to `~/.talon/workspace/notes/`
- âœ… `notes_search` - Search notes by keyword or tag
- âœ… `tasks_add` - Add tasks with priority levels
- âœ… `tasks_list` - List tasks filtered by status
- âœ… `tasks_complete` - Mark tasks as done

**Apple Integrations (macOS only):**
- âœ… `apple_notes_create` - Create notes in Apple Notes
- âœ… `apple_notes_search` - Search Apple Notes
- âœ… `apple_reminders_add` - Add reminders with due dates
- âœ… `apple_reminders_list` - List reminders by list
- âœ… `apple_reminders_complete` - Mark reminders complete
- âœ… `apple_calendar_create_event` - Create calendar events
- âœ… `apple_calendar_list_events` - List upcoming events
- âœ… `apple_calendar_delete_event` - Delete events

**Total:** 13 productivity tools implemented

---

### 3. Browser Control âœ… COMPLETE

**Status:** âœ… Fully implemented in v0.3.1

**What Was Built:**
```
src/tools/
â””â”€â”€ browser.ts        # Puppeteer automation âœ…
```

**Implemented Tools:**
- âœ… `browser_navigate` - Open URLs
- âœ… `browser_click` - Click elements by selector
- âœ… `browser_type` - Type text into inputs
- âœ… `browser_screenshot` - Capture screenshots
- âœ… `browser_extract` - Extract page content

**Features:**
- Headless/headed mode
- Custom viewport sizes
- Auto-launch browser
- Full page automation
- 100% test coverage

---

### 4. Shadow Loop âœ… COMPLETE

**Status:** âœ… Fully implemented in v0.3.1

**What Was Built:**
```
src/shadow/
â”œâ”€â”€ watcher.ts        # Filesystem monitoring âœ…
â”œâ”€â”€ heuristics.ts     # Event filtering âœ…
â”œâ”€â”€ ghost.ts          # Proactive messaging âœ…
â””â”€â”€ index.ts          # Integration âœ…
```

**Features:**
- Watches workspace for file changes
- Smart heuristics filter interesting events
- Sends proactive "ghost messages"
- Configurable paths and ignore patterns
- 85.8% test coverage (32 tests)

---

### 5. Smart Routing & Budget Mode âŒ

**Status:** Router exists, but no auto-detection

**What Needs to Be Built:**
```
src/agent/routing-heuristics.ts   # Auto-detect task type
src/utils/budget.ts               # Cost tracking
```

**Features Needed:**
- Auto-route by task type (research â†’ GPT-5 Nano, code â†’ Claude)
- Budget mode toggle (cheap vs powerful models)
- Cost estimation per conversation
- `/budget` command to show spending

**Current State:**
- âœ… Multi-provider routing (DeepSeek â†’ OpenRouter â†’ OpenAI)
- âœ… Automatic fallback system
- âœ… Subagent delegation for cost optimization
- âŒ No automatic task-type detection
- âŒ No budget tracking UI

---

### 6. Advanced Memory Features âŒ

**Status:** Basic compression works, but missing structured format

**What Needs to Be Built:**
- Structured memory summary (JSON format from doc)
- Auto-fact extraction
- User profile tracking
- Decision logging

**Current State:**
- âœ… Basic text summarization
- âœ… Memory compression (â‰¤800 tokens)
- âœ… Context window management
- âŒ No structured JSON format
- âŒ No automatic fact extraction
- âŒ No user profile tracking

---

## ğŸ“‹ Implementation Priority

### Phase 1: Subagents âœ… COMPLETE
1. âœ… Build `src/subagents/base.ts`
2. âœ… Implement 5 subagents (research, writer, planner, critic, summarizer)
3. âœ… Add task delegation to agent loop
4. âœ… 19 tests passing

### Phase 2: Productivity Tools âœ… COMPLETE
1. âœ… Notes tool (`notes_save`, `notes_search`)
2. âœ… Tasks tool (`tasks_add`, `tasks_list`, `tasks_complete`)
3. âœ… Apple integrations (8 tools for Notes, Reminders, Calendar)

### Phase 3: Browser Control âœ… COMPLETE
1. âœ… Puppeteer integration
2. âœ… 5 browser automation tools
3. âœ… 100% test coverage

### Phase 4: Shadow Loop âœ… COMPLETE
1. âœ… Filesystem watcher
2. âœ… Heuristic engine
3. âœ… Ghost messenger
4. âœ… 85.8% test coverage

### Phase 5: Smart Routing (Low Priority) âŒ
1. âŒ Auto-routing heuristics
2. âŒ Budget tracking
3. âŒ Cost estimation UI

### Phase 6: Advanced Memory (Low Priority) âŒ
1. âŒ Structured JSON memory format
2. âŒ Auto-fact extraction
3. âŒ User profile tracking

---

## ğŸ“Š Current Progress: ~85% Complete

**What Works:**
- Agent loop with tool calling âœ…
- Memory compression âœ…
- Model routing with fallback âœ…
- Web search (4 providers) âœ…
- File/shell/memory tools âœ…
- **Subagent delegation (5 agents, 97% savings)** âœ…
- **Productivity tools (13 tools)** âœ…
- **Browser automation (5 tools)** âœ…
- **Shadow Loop (proactive intelligence)** âœ…
- **Multi-channel (CLI, TUI, Telegram, WhatsApp)** âœ…
- **Service management (LaunchAgent/systemd)** âœ…
- **323 tests (100% passing)** âœ…

**What's Missing:**
- Auto-routing heuristics âŒ
- Budget tracking UI âŒ
- Structured memory format âŒ
- Auto-fact extraction âŒ
- User profile tracking âŒ

---

## ğŸ¯ Version Progress

- **v0.2.x**: 70% complete (foundation + routing)
- **v0.3.1**: 85% complete (Shadow Loop, Browser, Subagents, Productivity)
- **v1.0**: 100% (all planned features)

**Current Stats:**
- 70 source files
- 26+ tools
- 5 subagents
- 8 Apple integrations
- 323 tests
- 3 channels

---

## Secret Sauce: Memory Strategy (How You Beat OpenClaw)

### The Rule: Never Send Full Chat History

OpenClaw sends everything â†’ Expensive and slow
Kimi sends minimal context â†’ Cheap and fast

**What gets sent to LLM:**
1. **System prompt** (~500 tokens)
2. **Memory summary** (max 800 tokens)
3. **Last 5-10 messages** (~300-600 tokens)
4. **Tool results** (truncated to essentials)

**Total: ~1600-2000 tokens per request** vs OpenClaw's 8000+

### Memory Compression Strategy

Every N messages, compress the conversation:

```
Old Messages (20+)
       â”‚
       â–¼
[Memory Manager] â†’ Summarize into structured format
       â”‚
       â–¼
Structured Memory Summary (replaces raw messages)
```

**Memory Summary Format:**
```typescript
interface MemorySummary {
  // Who you are and what you want
  userProfile: {
    name?: string;
    goals: string[];
    preferences: string[];  // "Prefers arrow functions", "Hates boilerplate"
    communicationStyle: string;  // "Direct, no fluff"
  };
  
  // What we're working on now
  currentTask: {
    description: string;
    startedAt: Date;
    progress: string;
    blockers?: string[];
  };
  
  // Key decisions made
  decisions: Array<{
    timestamp: Date;
    context: string;
    decision: string;
    rationale: string;
  }>;
  
  // Important facts to remember
  facts: Array<{
    category: string;  // "technical", "personal", "project"
    content: string;
    importance: "critical" | "high" | "medium";
  }>;
  
  // What's next
  nextSteps: string[];
  
  // When this summary was created
  generatedAt: Date;
}
```

**Example Memory Summary:**
```json
{
  "userProfile": {
    "name": "Orlando",
    "goals": ["Build personal agent system", "Keep costs low"],
    "preferences": ["Direct advice, no fluff", "TypeScript over JavaScript"],
    "communicationStyle": "Concise, technical"
  },
  "currentTask": {
    "description": "Building OpenClaw-lite with low cost",
    "startedAt": "2026-02-16",
    "progress": "Architecture complete, starting implementation",
    "blockers": []
  },
  "decisions": [
    {
      "timestamp": "2026-02-16T10:00:00Z",
      "context": "Model selection for cost optimization",
      "decision": "Use GPT-5 Nano for subagents, Gemini Flash Lite for main",
      "rationale": "Token cost dominated by input; subagents don't need reasoning"
    }
  ],
  "facts": [
    {
      "category": "technical",
      "content": "Input tokens cost 3x more than output tokens",
      "importance": "critical"
    },
    {
      "category": "technical", 
      "content": "Tool logs must be truncated before sending to LLM",
      "importance": "high"
    }
  ],
  "nextSteps": [
    "Implement router",
    "Implement memory compression",
    "Build subagent system"
  ]
}
```

**Benefits:**
- 10x smaller than raw chat history
- Structured for easy parsing
- Captures intent, not just text
- Automatically updated

---

## Model Routing Strategy

**Don't use one model for everything. Route intelligently.**

### Routing Rules

| Task Type | Model | Cost | Reason |
|-----------|-------|------|--------|
| **Main Agent** (default) | Gemini Flash Lite | $0.0001/1K tokens | Fast, cheap, good enough |
| **Subagents** (always) | GPT-5 Nano | $0.00001/1K tokens | Cheapest possible |
| **Heavy Reasoning** | DeepSeek V3.2 | $0.0005/1K tokens | Only when needed |
| **Code Generation** | Claude 3.5 Sonnet | $0.003/1K tokens | Best code quality |
| **Memory Compression** | GPT-4o Mini | $0.00015/1K tokens | Fast summarization |

### When to Route

```typescript
interface RoutingDecision {
  task: string;
  complexity: 'simple' | 'medium' | 'complex';
  requiresReasoning: boolean;
  isCode: boolean;
  recommendedModel: string;
  estimatedCost: number;
}

// Examples:
// "Summarize this article" â†’ GPT-5 Nano (subagent)
// "Fix this bug" â†’ Claude 3.5 Sonnet (reasoning + code)
// "What files are in this directory?" â†’ Gemini Flash Lite (main)
// "Design a system architecture" â†’ DeepSeek V3.2 (complex reasoning)
```

**Auto-Routing Heuristics:**
- Contains "design", "architecture", "plan" â†’ DeepSeek
- Contains "summarize", "extract", "categorize" â†’ GPT-5 Nano
- Contains code blocks or "implement", "write function" â†’ Claude
- Everything else â†’ Gemini Flash Lite

---

## Directory Structure

```
kimi/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli/                    # Command-line interface
â”‚   â”‚   â”œâ”€â”€ index.ts           # Entry point, REPL loop
â”‚   â”‚   â”œâ”€â”€ commands.ts        # /commands (/reset, /compact, etc)
â”‚   â”‚   â””â”€â”€ display.ts         # Pretty printing, colors
â”‚   â”‚
â”‚   â”œâ”€â”€ agent/                  # AI agent runtime
â”‚   â”‚   â”œâ”€â”€ runtime.ts         # Main agent loop
â”‚   â”‚   â”œâ”€â”€ llm.ts             # LLM client (OpenAI/Anthropic/Local)
â”‚   â”‚   â”œâ”€â”€ router.ts          # Model routing logic
â”‚   â”‚   â”œâ”€â”€ tokenizer.ts       # Token counting for context
â”‚   â”‚   â””â”€â”€ prompts.ts         # System prompts
â”‚   â”‚
â”‚   â”œâ”€â”€ subagents/              # Lightweight subagents (GPT-5 Nano)
â”‚   â”‚   â”œâ”€â”€ base.ts            # Base subagent class
â”‚   â”‚   â”œâ”€â”€ research.ts        # Web research subagent
â”‚   â”‚   â”œâ”€â”€ writer.ts          # Content writing subagent
â”‚   â”‚   â”œâ”€â”€ coder.ts           # Code generation subagent
â”‚   â”‚   â””â”€â”€ planner.ts         # Task planning subagent
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                  # Tool implementations
â”‚   â”‚   â”œâ”€â”€ registry.ts        # Tool registration & discovery
â”‚   â”‚   â”œâ”€â”€ file.ts            # Read, write, edit, list files
â”‚   â”‚   â”œâ”€â”€ shell.ts           # Execute shell commands
â”‚   â”‚   â”œâ”€â”€ browser.ts         # Web browsing (Puppeteer/Playwright)
â”‚   â”‚   â”œâ”€â”€ websearch.ts       # Web search tool
â”‚   â”‚   â””â”€â”€ memory.ts          # Memory recall tool
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/                 # Memory management
â”‚   â”‚   â”œâ”€â”€ store.ts           # Conversation storage
â”‚   â”‚   â”œâ”€â”€ compressor.ts      # Memory compression (summarization)
â”‚   â”‚   â”œâ”€â”€ summary.ts         # Structured summary format
â”‚   â”‚   â””â”€â”€ context.ts         # Context window management
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                 # Configuration
â”‚   â”‚   â”œâ”€â”€ index.ts           # Config loader
â”‚   â”‚   â””â”€â”€ defaults.ts        # Default settings
â”‚   â”‚
â”‚   â””â”€â”€ utils/                  # Utilities
â”‚       â”œâ”€â”€ logger.ts
â”‚       â””â”€â”€ errors.ts
â”‚
â”œâ”€â”€ skills/                     # Skills directory (auto-created)
â”‚   â””â”€â”€ example/
â”‚       â””â”€â”€ SKILL.md
â”‚
â”œâ”€â”€ .kimi/                      # Runtime data (auto-created)
â”‚   â”œâ”€â”€ config.json            # User config
â”‚   â”œâ”€â”€ conversations/         # Chat history
â”‚   â”œâ”€â”€ memory/                # Long-term memories
â”‚   â””â”€â”€ workspace/             # Agent workspace
â”‚
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

---

## Component Breakdown

### 1. CLI Layer (`src/cli/`)

**Purpose**: Interactive terminal interface

**Key Features**:
- REPL (Read-Eval-Print Loop)
- Command parsing (`/reset`, `/compact`, `/model`, etc.)
- Streaming output from LLM
- Syntax highlighting for code blocks

**Interface**:
```typescript
interface CLI {
  start(): Promise<void>;
  displayMessage(role: 'user' | 'assistant', content: string): void;
  displayToolCall(tool: string, params: any): void;
  displayToolResult(result: any): void;
  displayError(error: Error): void;
}
```

**Commands**:
```
/reset              - Clear conversation history
/compact           - Summarize and truncate context
/model <name>      - Switch LLM model
/config            - Show/edit configuration
/tools             - List available tools
/history           - Show conversation history
/exit, /quit       - Exit Kimi
```

### 2. Agent Runtime (`src/agent/`)

**Purpose**: Core AI logic - processes user input and orchestrates tools

**Flow**:
```
1. Receive user message
2. Load conversation context from memory
3. Send to LLM with tool descriptions
4. Parse response:
   - If text â†’ display to user
   - If tool call â†’ execute tool â†’ send result back to LLM â†’ repeat
5. Save interaction to memory
```

**Key Design**:
- Single session (no multi-user complexity)
- Tool use is mandatory (agent MUST use tools to accomplish tasks)
- Streaming responses for better UX
- Automatic context window management

**LLM Integration**:
```typescript
interface LLMClient {
  chat(messages: Message[], tools: Tool[]): AsyncIterable<LLMChunk>;
  countTokens(text: string): number;
}

// Support multiple providers via unified interface
class AnthropicClient implements LLMClient { }
class OpenAIClient implements LLMClient { }
class OllamaClient implements LLMClient { }
```

### 3. Tool System (`src/tools/`)

**Purpose**: Agent capabilities - the "hands" of the AI

**MVP Tools** (build these first - maximum impact):

#### Productivity Tools
```typescript
// notes.save - Save a note
{
  name: 'notes_save',
  description: 'Save a note to your knowledge base',
  parameters: {
    title: string,
    content: string,
    tags?: string[]
  }
}

// notes.search - Search notes
{
  name: 'notes_search',
  description: 'Search through saved notes',
  parameters: {
    query: string,
    limit?: number
  }
}
```

#### Research Tools
```typescript
// web.search - Search the web
{
  name: 'web_search',
  description: 'Search the web for information',
  parameters: {
    query: string,
    numResults?: number  // Default: 5
  },
  returns: {
    results: Array<{
      title: string,
      url: string,
      snippet: string
    }>
  }
}

// web.open - Open and extract webpage
{
  name: 'web_open',
  description: 'Open a URL and extract the main content',
  parameters: {
    url: string,
    maxLength?: number  // Truncate long pages
  },
  returns: {
    title: string,
    content: string,     // Extracted text (truncated)
    links: string[]      // Important links found
  }
}
```

#### Planning Tools
```typescript
// tasks.add - Add a task
{
  name: 'tasks_add',
  description: 'Add a task to your todo list',
  parameters: {
    title: string,
    description?: string,
    priority?: 'low' | 'medium' | 'high'
  }
}

// tasks.list - List tasks
{
  name: 'tasks_list',
  description: 'List your tasks',
  parameters: {
    status?: 'pending' | 'completed' | 'all',
    limit?: number
  }
}

// tasks.complete - Mark task done
{
  name: 'tasks_complete',
  description: 'Mark a task as completed',
  parameters: {
    taskId: string
  }
}
```

#### Utility Tools
```typescript
// summarize - Summarize text
{
  name: 'summarize',
  description: 'Summarize long text into key points',
  parameters: {
    text: string,
    maxLength?: number,     // Max words in summary
    format?: 'bullet' | 'paragraph'
  }
}

// extract_action_items - Extract todos
{
  name: 'extract_action_items',
  description: 'Extract action items from text',
  parameters: {
    text: string
  },
  returns: {
    actionItems: string[]
  }
}
```

**File Tools** (Phase 1.5 - after MVP)
```typescript
// file_read, file_write, file_edit, file_list
// Keep minimal - just read/write/edit
```

**Shell Tool** (Phase 1.5 - after MVP)
```typescript
// shell_execute - Run commands
// With confirmation for destructive operations
```

**Why These Tools First?**
- `web.search` â†’ Makes it instantly useful (research anything)
- `notes.save/search` â†’ Builds your knowledge base over time
- `tasks.add/list` â†’ Practical daily productivity
- `summarize/extract_action_items` â†’ Processing information efficiently

**Result**: Even with just these 6 tools, it's already more useful than OpenClaw for daily tasks.

### 4. Subagent System (`src/subagents/`)

**Purpose**: Lightweight task-specific agents that handle focused work

**The OpenClaw Pattern:**
```
Main Agent (Gemini Flash Lite)
       â”‚
       â”œâ”€â”€â”€â”€â”€â–º Research Subagent (GPT-5 Nano) â†’ Structured result
       â”‚
       â”œâ”€â”€â”€â”€â”€â–º Writer Subagent (GPT-5 Nano) â†’ Structured result
       â”‚
       â”œâ”€â”€â”€â”€â”€â–º Coder Subagent (Claude 3.5) â†’ Structured result
       â”‚
       â””â”€â”€â”€â”€â”€â–º Planner Subagent (DeepSeek) â†’ Structured result
```

**Why Subagents?**
- 10x cheaper (GPT-5 Nano vs main model)
- Prevents token bloat (focused tasks = short responses)
- Structured output (JSON, not prose)
- Parallel execution possible

**Subagent Interface:**
```typescript
interface Subagent {
  name: string;
  model: string;           // GPT-5 Nano, Claude, etc.
  systemPrompt: string;
  
  // Execute with minimal context
  execute(task: string, context: MinimalContext): Promise<SubagentResult>;
}

interface SubagentResult {
  // Always structured JSON
  summary: string;              // Brief description of work done
  result: any;                  // Task-specific output
  confidence: number;           // 0-1 confidence score
  
  // Optional fields per subagent type
  actionItems?: string[];       // For research/planning
  code?: string;                // For coder
  risks?: string[];             // For planner
  recommendedNextStep?: string; // For all subagents
}

interface MinimalContext {
  // Only what's needed - NOT full history
  userMessage: string;
  relevantFacts: string[];      // From memory
  currentTask?: string;         // From memory summary
}
```

**Example Subagent: ResearchAgent**
```typescript
class ResearchSubagent implements Subagent {
  name = 'research';
  model = 'openai/gpt-5-nano';
  
  systemPrompt = `You are a research assistant. Given a query, search the web and return structured findings.
  
  Rules:
  - Use web_search tool to find information
  - Summarize in 2-3 sentences max
  - Return ONLY valid JSON
  
  Output format:
  {
    "summary": "Brief summary of findings",
    "sources": ["url1", "url2"],
    "keyFacts": ["fact1", "fact2"],
    "recommendedNextStep": "What to do with this info"
  }`;
  
  async execute(task: string, context: MinimalContext): Promise<SubagentResult> {
    // 1. Search web
    // 2. Extract key info
    // 3. Return structured JSON
    // Cost: ~$0.0001 vs $0.01 for main agent
  }
}
```

**Example Usage:**
```typescript
// User asks: "Research the best React state management libraries"

// Main agent routes to ResearchSubagent
const research = await subagents.research.execute(
  "Research React state management libraries",
  {
    userMessage: "Research the best React state management libraries",
    relevantFacts: ["User prefers lightweight solutions"],
    currentTask: "Building a React app"
  }
);

// Research returns:
{
  "summary": "Zustand and Jotai are lightweight favorites in 2026",
  "sources": ["npm trends", "GitHub stars"],
  "keyFacts": ["Zustand: 50KB, 50k stars", "Jotai: atomic approach"],
  "recommendedNextStep": "Compare bundle sizes and API simplicity"
}

// Main agent then routes to WriterSubagent or responds directly
```

**Subagent Registry:**
```typescript
const subagents = {
  research: new ResearchSubagent(),      // Web research
  writer: new WriterSubagent(),          // Content creation
  coder: new CoderSubagent(),            // Code generation
  planner: new PlannerSubagent(),        // Task planning
  summarizer: new SummarizerSubagent(),  // Text compression
};

// Usage in main agent:
if (needsResearch(userQuery)) {
  const result = await subagents.research.execute(task, context);
  // Inject result into main agent context
}
```

### 5. Memory System (`src/memory/`)

**Purpose**: Aggressive context compression to minimize token costs

**The Strategy: Never Send Full History**

```
Traditional (OpenClaw):
System Prompt + Full History (50 messages) + Tools = 8000+ tokens

Kimi (Smart Compression):
System Prompt + Memory Summary (800 tokens) + Last 5 Messages + Tools = 1600 tokens
                                                        
Result: 80% cost reduction
```

**Three-Tier System:**

#### Tier 1: Recent Messages (Sliding Window)
- Keep only last **5-10 messages** in context
- These are the "working memory"
- Automatically drops old messages (not deleted, just not sent)

#### Tier 2: Memory Summary (Compressed Context)
- Structured summary updated every N messages
- Contains: user profile, current task, decisions, facts, next steps
- Max 800 tokens
- Replaces raw message history

#### Tier 3: Persistent Storage
- Raw message logs (for reference, not sent to LLM)
- Important facts database
- Conversation archives

**Memory Compression Algorithm:**
```typescript
class MemoryCompressor {
  // Trigger compression every 10 messages
  private readonly COMPRESSION_THRESHOLD = 10;
  
  async compress(messages: Message[]): Promise<MemorySummary> {
    // 1. Take last 20 messages
    const toCompress = messages.slice(0, -5);  // Keep last 5
    
    // 2. Use cheap model for summarization
    const summary = await this.llm.chat({
      model: 'openai/gpt-4o-mini',  // Cheap!
      messages: [{
        role: 'system',
        content: `Compress this conversation into a structured summary.
        
        Extract:
        - User profile info (name, preferences, style)
        - Current task/context
        - Key decisions made
        - Important facts to remember
        - Next steps
        
        Output as JSON.`
      }, {
        role: 'user',
        content: JSON.stringify(toCompress)
      }]
    });
    
    // 3. Parse and validate
    return JSON.parse(summary) as MemorySummary;
  }
}
```

**Storage Format:**
```typescript
interface MemoryStore {
  // Current session (minimal)
  currentSession: {
    summary: MemorySummary;      // 800 tokens max
    recentMessages: Message[];   // Last 5-10 only
    totalMessages: number;       // Count for UI
  };
  
  // Archive (not sent to LLM)
  archive: {
    id: string;
    date: Date;
    messageCount: number;
    summary: MemorySummary;
    fullLog: Message[];          // Only if user asks for /history
  }[];
  
  // Facts database
  facts: {
    id: string;
    content: string;
    category: 'user' | 'project' | 'technical';
    importance: 'critical' | 'high' | 'medium';
    createdAt: Date;
  }[];
}
```

**Auto-Extraction:**
```typescript
// After each assistant response, extract facts
async function extractFacts(message: string): Promise<string[]> {
  const result = await subagents.summarizer.execute(
    `Extract important facts from this message that should be remembered long-term.
     Return as JSON array of strings.`,
    { userMessage: message }
  );
  
  return JSON.parse(result.result);
}

// Store extracted facts
for (const fact of extractedFacts) {
  await memory.storeFact(fact, 'auto-extracted');
}
```

**Auto-memory**: Agent automatically extracts and stores important facts

### 5. Configuration (`src/config/`)

**Purpose**: User preferences and settings

**Config file**: `~/.kimi/config.json`

```json
{
  "llm": {
    "provider": "anthropic",
    "model": "claude-3-5-sonnet-20241022",
    "apiKey": "sk-ant-...",
    "maxTokens": 4096,
    "temperature": 0.7
  },
  "context": {
    "maxMessages": 50,
    "autoCompactThreshold": 40,
    "summarizationModel": "claude-3-haiku-20240307"
  },
  "tools": {
    "shell": {
      "requireConfirmation": true,
      "allowedCommands": ["*"],
      "blockedCommands": ["rm -rf /", "sudo"]
    },
    "browser": {
      "headless": true,
      "defaultViewport": { "width": 1280, "height": 720 }
    }
  },
  "memory": {
    "enabled": true,
    "autoExtractFacts": true
  },
  "ui": {
    "theme": "dark",
    "showToolCalls": true,
    "streaming": true
  }
}
```

---

## Data Flow

```
User Input
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLI Layer  â”‚  â†’ Parse commands (/reset, /compact)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Agent    â”‚  â†’ Load context, send to LLM
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM API    â”‚  â†’ Streaming response
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â–º Text response â”€â”€â”€â”€â–º Display to user
       â”‚
       â””â”€â”€â”€â”€â”€â”€â–º Tool call â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   Tool      â”‚  â†’ Execute (file, shell, browser)
                          â”‚  Registry   â”‚
                          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   Result    â”‚  â†’ Back to Agent
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Technology Stack

| Component | Technology | Reason |
|-----------|-----------|--------|
| Language | TypeScript | Type safety, great ecosystem |
| Runtime | Node.js 18+ | Native async/await, good performance |
| CLI | `readline` + `chalk` | Native Node.js, colors/formatting |
| LLM SDK | `@anthropic-ai/sdk`, `openai` | Official SDKs |
| Web Search | API (Serper/Tavily) | Week 1: Simple API call |
| Storage | JSON files | Simple, no DB needed |
| Config | Simple JSON | No complexity |

**Intentionally NOT using (yet):**
- Puppeteer/Playwright (Week 4, if needed)
- SQLite (not needed for single user)
- Complex frameworks (YAGNI)
- Vector DB (semantic search is Phase 3)

---

## Minimal Package.json

```json
{
  "name": "kimi",
  "version": "0.1.0",
  "description": "Personal AI assistant that beats OpenClaw",
  "type": "module",
  "main": "./dist/cli/index.js",
  "bin": {
    "kimi": "./dist/cli/index.js"
  },
  "scripts": {
    "build": "tsc",
    "dev": "tsx src/cli/index.ts",
    "start": "node dist/cli/index.js",
    "typecheck": "tsc --noEmit"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.27.0",
    "openai": "^4.0.0",
    "chalk": "^5.3.0",
    "commander": "^12.0.0",
    "dotenv": "^16.4.0"
  },
  "devDependencies": {
    "@types/node": "^20.0.0",
    "tsx": "^4.0.0",
    "typescript": "^5.5.0"
  }
}
```

**Note**: Web search uses API (Serper, Tavily, or Exa) rather than Puppeteer for reliability:
```typescript
// Week 1: Use API-based search
const search = await fetch('https://google.serper.dev/search', {
  method: 'POST',
  headers: { 'X-API-KEY': config.serperApiKey },
  body: JSON.stringify({ q: query })
});

// Week 4: Add browser automation if needed
```

---

## 4-Week Deliberate Practice Plan

### Week 1: Build the Core Agent Loop
**Goal**: Basic working agent with tool calling

**Day 1-2: Setup & Config**
- `config/index.ts` - Load configuration (models, API keys)
- `cli/index.ts` - REPL loop with basic input/output
- Set up project structure

**Day 3-4: LLM Integration**
- `agent/llm.ts` - LLM client supporting multiple providers
- `agent/prompts.ts` - System prompts
- Test: Can you chat with the model?

**Day 5-7: Tool System**
- `tools/registry.ts` - Tool registration and execution
- `tools/websearch.ts` - Web search (the most important tool)
- `agent/runtime.ts` - Main agent loop with tool calling
- **Milestone**: Can ask "What is React?" and get web results

**End of Week 1 Deliverable**: 
```
> What is the latest version of TypeScript?
[Tool: web_search] TypeScript latest version
Latest TypeScript version is 5.7.3 released January 2025...
```

---

### Week 2: Add Memory Compression
**Goal**: Smart memory that minimizes token costs

**Day 1-2: Memory System**
- `memory/store.ts` - Save conversations to disk
- `memory/summary.ts` - Structured memory format

**Day 3-4: Compression Engine**
- `memory/compressor.ts` - Summarize old messages
- `memory/context.ts` - Context window management
- **Key**: Keep only last 5-10 messages in context

**Day 5-7: Integration**
- Wire compression into agent loop
- Add `/compact` command
- Test: Have long conversation, verify context stays small
- **Milestone**: 20+ message conversation costs same as 5 messages

**End of Week 2 Deliverable**:
```
Conversation: 25 messages
Context sent to LLM: 1600 tokens (not 8000+)
Cost: $0.003 (not $0.015)
```

---

### Week 3: Add Subagents
**Goal**: Task delegation for efficiency

**Day 1-2: Subagent Framework**
- `subagents/base.ts` - Base subagent class
- `agent/router.ts` - Route tasks to subagents

**Day 3-4: Build Subagents**
- `subagents/research.ts` - Web research (GPT-5 Nano)
- `subagents/summarizer.ts` - Text compression (GPT-5 Nano)

**Day 5-7: Advanced Subagents**
- `subagents/writer.ts` - Content creation
- `subagents/planner.ts` - Task planning (DeepSeek when needed)
- **Milestone**: "Research TypeScript decorators" â†’ subagent does it â†’ returns structured result

**End of Week 3 Deliverable**:
```
> Research best React state management
[Subagent: research] Executing...
[Subagent returned] Summary: Zustand and Jotai lead in 2026...
[Main agent] Based on the research, Zustand is best for your use case...
```

---

### Week 4: Add Routing + Budget Mode
**Goal**: Smart model selection for cost optimization

**Day 1-2: Model Router**
- `agent/router.ts` - Auto-detect task type
- Route simple tasks â†’ GPT-5 Nano
- Route code tasks â†’ Claude 3.5
- Route reasoning â†’ DeepSeek

**Day 3-4: Budget Mode**
- Track token usage per conversation
- Show cost estimates
- Set spending limits
- `/budget` command

**Day 5-7: Polish & Tools**
- Add remaining productivity tools:
  - `tools/notes.ts` - Save/search notes
  - `tools/tasks.ts` - Todo list
- Add productivity commands:
  - `/notes` - Show recent notes
  - `/tasks` - Show task list
- **Milestone**: Daily productivity workflow works

**End of Week 4 Deliverable**: **You have OpenClaw**

---

## Implementation Priority (File Order)

### Week 1 Files
1. `config/index.ts` - Configuration loader
2. `cli/index.ts` - REPL interface
3. `agent/llm.ts` - LLM client
4. `tools/registry.ts` - Tool system
5. `tools/websearch.ts` - Web search tool â­ MVP critical
6. `agent/runtime.ts` - Main agent loop

### Week 2 Files
7. `memory/store.ts` - Conversation persistence
8. `memory/summary.ts` - Structured memory format
9. `memory/compressor.ts` - Compression logic
10. `memory/context.ts` - Context management

### Week 3 Files
11. `subagents/base.ts` - Subagent base class
12. `subagents/research.ts` - Research subagent
13. `subagents/summarizer.ts` - Summarizer subagent
14. `agent/router.ts` - Task routing

### Week 4 Files
15. `subagents/writer.ts` - Writer subagent
16. `subagents/planner.ts` - Planner subagent
17. `tools/notes.ts` - Notes tool
18. `tools/tasks.ts` - Task management tool
19. `utils/budget.ts` - Cost tracking

---

## Example Session

```bash
$ kimi

ğŸ¤– Kimi v0.1.0 | Model: gemini-flash-lite | Cost: $0.002
Memory: 10 messages | Context: 1,400 tokens

> What are the best practices for React hooks in 2026?

[Subagent: research] Searching for latest React hooks best practices...
[Subagent returned] 5 key findings from 2026

Based on the research, here are the 2026 best practices:

1. Use useMemo for expensive computations (still relevant)
2. React Forget compiler handles most optimizations now
3. use hook for data fetching is preferred over useEffect
4. Server Components reduce client-side hook complexity
5. Custom hooks should follow the "single responsibility" principle

[Tool: notes_save] Saved to your knowledge base

> Save that for later

âœ“ Note saved: "React Hooks Best Practices 2026"

> Create a task to refactor my project

[Tool: tasks_add] Created task
Title: Refactor project with 2026 React best practices
Priority: medium

> Add another: Research Zustand vs Redux

[Tool: tasks_add] Created task
Title: Research Zustand vs Redux
Priority: high

> Show my tasks

[Tool: tasks_list] Your tasks:

ğŸ”´ High Priority:
  â€¢ Research Zustand vs Redux

ğŸŸ¡ Medium Priority:
  â€¢ Refactor project with 2026 React best practices

> /status

ğŸ“Š Session Status:
Model: gemini-flash-lite
Messages: 6
Context Size: 1,400 tokens (80% savings vs full history)
Total Cost: $0.002
Subagents Used: 1

Memory Summary:
â€¢ Working on: React project modernization
â€¢ Preferences: Direct answers, code examples
â€¢ Recent: Learned 2026 hooks best practices

> Research Zustand vs Redux

[Subagent: research] Analyzing state management options...
[Subagent returned] Structured comparison

Recommendation: Zustand for your use case
- Smaller bundle (1KB vs 11KB)
- Simpler API
- Better TypeScript support
- Sufficient for your app size

[Tool: tasks_complete] Marked "Research Zustand vs Redux" as complete

> /compact

ğŸ”„ Compressing conversation...
[Subagent: summarizer] Creating memory summary...
âœ“ Compressed 8 messages into structured summary
Context reduced: 2,800 â†’ 1,200 tokens

> /budget

ğŸ’° Budget Status:
Session Cost: $0.004
- Main agent: $0.003 (Gemini Flash Lite)
- Subagents: $0.001 (GPT-5 Nano x2)
- Savings: 85% vs using single expensive model

Monthly Budget: $5.00
Spent: $0.12 (2%)

> /exit

ğŸ‘‹ Goodbye! 
ğŸ’¾ Conversation saved
ğŸ’° Session cost: $0.004 (85% cheaper than OpenClaw)
```

---

## Why This Beats OpenClaw

### Cost Comparison (1 Hour Session)

| Metric | OpenClaw | Kimi | Savings |
|--------|----------|------|---------|
| **Context Size** | 8,000 tokens | 1,600 tokens | 80% â†“ |
| **Model Strategy** | Single expensive model | Smart routing | 70% â†“ |
| **Subagent Cost** | Main model does everything | GPT-5 Nano | 95% â†“ |
| **Total Cost** | $0.15/hour | $0.03/hour | **85% â†“** |

### Key Differentiators

**1. Aggressive Memory Compression**
- OpenClaw: Sends full history (gets expensive fast)
- Kimi: Structured summaries only (constant cost)

**2. Model Routing**
- OpenClaw: One model for everything
- Kimi: Right tool for the job (cheap for simple tasks)

**3. Subagent Architecture**
- OpenClaw: Single agent handles all
- Kimi: Delegates to focused subagents (cheaper + better)

**4. Minimal Context Philosophy**
- OpenClaw: "Remember everything"
- Kimi: "Remember what matters" (structured, compressed)

### What Makes It Feel Intelligent

Not the model. The **workflow**:

```
plan â†’ execute â†’ evaluate â†’ refine
```

Plus:
- **Delegation**: Break complex tasks into subtasks
- **Tool Usage**: Use right tool for each job
- **Iterative Improvement**: Learn from each interaction
- **Memory**: Remember context without bloat

This is the "agentic effect" - feels smart because it works smart.

---

## Future Enhancements (Post-MVP)

### Phase 2 (Month 2)
- **File tools**: Read, write, edit code
- **Shell execution**: Run commands with confirmation
- **Git integration**: Commit, branch, PR operations
- **Browser control**: Full Puppeteer automation

### Phase 3 (Month 3)
- **Skills system**: Dynamic tool loading
- **Multiple sessions**: Project-specific contexts
- **Semantic search**: Vector embeddings for memory
- **Web UI**: Browser interface alongside CLI

### Phase 4 (Month 4+)
- **Voice mode**: Speech-to-text input
- **Advanced subagents**: Coder, Reviewer, Tester
- **Workflow automation**: Save and replay task sequences
- **Team features**: Multi-user (if needed)

---

## Quick Start (Do This Now)

### 1. Create Project
```bash
mkdir kimi && cd kimi
npm init -y
npm install typescript tsx @anthropic-ai/sdk openai chalk
npx tsc --init
```

### 2. Add API Keys
```bash
# ~/.kimi/config.json
{
  "llm": {
    "provider": "openai",
    "model": "gpt-5-nano",
    "apiKey": "sk-..."
  }
}
```

### 3. Build Week 1
Follow the 4-week plan above. Start with:
- `config/index.ts`
- `cli/index.ts` 
- `agent/llm.ts`
- `tools/websearch.ts`
- `agent/runtime.ts`

**4 weeks later: You have a personal AI that beats OpenClaw.**

---

**Start Week 1 now?** I can generate the initial files if you want to begin.
